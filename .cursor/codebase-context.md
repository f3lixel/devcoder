# Codebase Context: felixel-dev (DevCoder)

## ğŸ¯ ProjektÃ¼bersicht
- **Name**: felixel-dev (DevCoder) - AI-powered Chat-Tool
- **Framework**: Next.js 15.5 (App Router, Turbopack)
- **Sprache**: TypeScript + React 19
- **Styling**: Tailwind CSS 4 + Shadcn UI
- **Backend**: Next.js Server Components + SSE Streaming
- **AI-Provider**: OpenRouter (Qwen3-Next-80B-A3B mit Reasoning)
- **Datenbank**: Supabase (Auth, Datenpeicherung)
- **Code-AusfÃ¼hrung**: Monaco Editor, Sandpack, xterm (Terminal)
- **State Management**: Zustand 5

---

## ğŸ“ Verzeichnisstruktur (Key Paths)

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ chat/route.ts          # Server-Streaming zur OpenRouter (HAUPTPFAD)
â”‚   â””â”€â”€ (layout/pages)             # Next.js Pages
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Assistant.tsx              # Haupt-Chat-Komponente (SSE-Handling)
â”‚   â”œâ”€â”€ ai-elements/               # Chat-UI-Komponenten (verbindlich)
â”‚   â”‚   â”œâ”€â”€ message.tsx            # Message-Bubbles (user/assistant)
â”‚   â”‚   â”œâ”€â”€ reasoning.tsx          # Thinking-Badge (ausklappbar)
â”‚   â”‚   â”œâ”€â”€ response.tsx           # Markdown/Streamdown-Renderer
â”‚   â”‚   â””â”€â”€ (weitere)
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ shadcn-io/             # Shadcn UI Components
â”‚   â””â”€â”€ (sonstige Komponenten)
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ ai-service.ts              # AI-Kontext/Code-Generierung (disabled)
â”‚   â”œâ”€â”€ supabase/                  # Supabase Client/Server/Service
â”‚   â””â”€â”€ (utilities)
â”œâ”€â”€ hooks/                         # Custom React Hooks
â”œâ”€â”€ mastra/                        # Mastra AI Framework Integration
â””â”€â”€ types/                         # TypeScript Definitionen
```

---

## ğŸ¤– AI-Streaming Architektur (PRODUKTIV)

### Fluss:
1. **Client** (`Assistant.tsx`):
   - Nutzer gibt Nachricht ein
   - `POST /api/chat` mit `{ messages: UIMessage[] }`
   - Erwartet `Content-Type: text/event-stream`

2. **Server** (`src/app/api/chat/route.ts`):
   - Proxyt zu OpenRouter
   - Modell: `qwen/qwen3-next-80b-a3b-thinking`
   - Reasoning aktiviert: `include_reasoning: true`, `reasoning: { effort: 'medium' }`
   - Streamt SSE-Events zurÃ¼ck

### SSE-Event-Format (Server â†’ Client):
```json
{"type":"status","message":"Analysiere Promptâ€¦"}
{"type":"stepStart","id":"generate"}
{"type":"reasoning","text":"Denke Ã¼ber Architektur nachâ€¦"}
{"type":"token","text":"Hier ist der Antworttextâ€¦"}
{"type":"stepDone","id":"generate"}
{"type":"done"}
```

### Client-Parser (Assistant.tsx):
- Liest `text/event-stream`
- Events nach `type` verarbeiten:
  - `token`: Append zu `assistantMessage.content`
  - `reasoning`: Append zu `assistantMessage.reasoning`
  - `status`: UI-Feedback
  - `stepStart/Done`: Progress-Tracking
  - `done`: Streaming beendet

---

## ğŸ¨ UI-Komponenten-Regeln (VERBINDLICH)

### Message-Bubbles
```tsx
import { Message, MessageAvatar, MessageContent } from '@/components/ai-elements/message'

<Message>
  <MessageAvatar role="user" />
  <MessageContent variant="contained">
    {text}
  </MessageContent>
</Message>
```
- Varianten: `contained` (Standard) | `flat`
- Padding: `px-4 py-3` bei `contained`

### Reasoning-Badge (Thinking)
```tsx
import { Reasoning, ReasoningTrigger, ReasoningContent } from '@/components/ai-elements/reasoning'

<Reasoning>
  <ReasoningTrigger>Show Thinking</ReasoningTrigger>
  <ReasoningContent>{reasoningText}</ReasoningContent>
</Reasoning>
```
- **Wichtig**: Reasoning-Text NICHT in Chat-Bubble wiederholen
- Auto-Open wÃ¤hrend Streaming, Auto-Close nach Ende
- Position: direkt vor korrespondierender Assistant-Bubble

### Markdown/Response-Rendering
```tsx
import { Response } from '@/components/ai-elements/response'

<Response content={streamedText} />
```
- Nutzt Streamdown fÃ¼r Markdown-Rendering
- KaTeX fÃ¼r Math-Rendering
- Syntax-Highlighting mit Shiki

---

## ğŸ”’ Sicherheits-Konventionen

- **API-Keys**: In `.env.local` (niemals committen)
  - `OPENROUTER_API_KEY` (fÃ¼r OpenRouter)
  - `NEXT_PUBLIC_SUPABASE_URL`
  - `NEXT_PUBLIC_SUPABASE_ANON_KEY` (public)
  - Service Keys niemals clientseitig nutzen

- **Edge Functions**: `ai-gateway` wurde entfernt â†’ produktiv nur `/api/chat`

---

## ğŸ“‹ Message-Datenstruktur

```ts
interface UIMessage {
  id: string
  role: 'user' | 'assistant' | 'system'
  content: string
  reasoning?: string          // Nur assistant, aus SSE
  files?: FileAttachment[]    // Datei-Uploads
  commands?: CommandExecution[] // Code-Execution Logs
  progress?: ProgressInfo[]   // Live-Status wÃ¤hrend Streaming
}
```

---

## ğŸ› ï¸ Typische Entwicklungs-Workflows

### 1. Neue Chat-Feature hinzufÃ¼gen
- Komponente in `src/components/` erstellen
- In `Assistant.tsx` integrieren
- Wenn Streaming betroffen: SSE-Events in `route.ts` anpassen

### 2. UI-Komponente Ã¤ndern
- **Bevorzugt**: Varianten in `ai-elements/` verwenden
- Keine Ã„nderungen ohne Grund an Message/Reasoning-Props

### 3. Reasoning-Flow debuggen
- PrÃ¼fen, ob Server `{"type":"reasoning","text":...}` sendet
- Wenn nicht: Provider sendet kein Reasoning fÃ¼r das Modell
- Denken-Text NIEMALS doppelt rendern

### 4. Performance optimieren
- `react-resizable-panels` fÃ¼r Layout-Management
- `use-stick-to-bottom` fÃ¼r Auto-Scroll
- Lazy-Loading fÃ¼r Code-Editor (Monaco)

---

## ğŸ“¦ Dependencies (wichtig)

| Package | Zweck |
|---------|-------|
| `@ai-sdk/react` | AI SDK fÃ¼r React (useChat Hook) |
| `@assistant-ui/react` | Chat-UI Patterns |
| `@monaco-editor/react` | Code-Editor |
| `@codesandbox/sandpack-react` | Live-Code-Execution |
| `xterm` | Terminal-Emulation |
| `@supabase/supabase-js` | Datenbank + Auth |
| `framer-motion` | Animations |
| `zustand` | State Management |
| `react-markdown` | Markdown-Rendering |
| `shiki` | Syntax-Highlighting |

---

## âš ï¸ HÃ¤ufige Probleme & LÃ¶sungen

| Problem | Ursache | LÃ¶sung |
|---------|--------|--------|
| Reasoning fehlt | Server sendet keine `type=reasoning`-Events | Modell/Prompt anpassen; `include_reasoning: true` prÃ¼fen |
| Keine Token im Chat | `Content-Type` ist nicht `text/event-stream` | PrÃ¼fen, dass `route.ts` SSE-Response setzt |
| Chat-Bubbles zu hoch | `prose`-Klasse mit Margins | `prose-p:my-0` hinzufÃ¼gen |
| Zu viele API-Calls | Streaming unterbrochen/nicht gestartet | SSE-Parser debuggen |

---

## ğŸ”— Important Files Quick Reference

| Datei | Zweck |
|-------|-------|
| `src/app/api/chat/route.ts` | Server-Streaming (OpenRouter Proxy) |
| `src/components/Assistant.tsx` | Chat-UI + SSE-Parsing |
| `src/components/ai-elements/message.tsx` | Message-Bubbles |
| `src/components/ai-elements/reasoning.tsx` | Thinking-Badge |
| `global_rules.md` | AI-Coding-Standards fÃ¼r dieses Projekt |
| `.env.local` | Secrets (nicht committen) |
| `package.json` | Dependencies |

---

## ğŸ“ FÃ¼r Cursor AI IDE

Diese Datei wird automatisch geladen. Nutze diese Informationen, um:
- âœ… Code-VorschlÃ¤ge im Kontext zu machen
- âœ… Komponenten konsistent zu erweitern
- âœ… SSE-Streaming korrekt zu implementieren
- âœ… UI-Regeln einzuhalten
- âœ… Sicherheit zu wahren

**Hinweis**: Immer `global_rules.md` konsultieren vor grÃ¶ÃŸeren Ã„nderungen.
